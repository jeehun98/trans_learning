# trans_learning

전이학습 소개
전통적인 머신러닝은 다음 그림과 같이 특정 도메인, 데이터, 작업에 국한해 각 모델을 훈련한다.


전이학습은 사람이 지식을 활용하는 것보다 직접적이고 발전된 방식으로 데이터를 배워 나간다. 따라서 전이학습은 다른 관련된 과제에 대한 지식이나 모델을 재사용하는 하나의 방법이 된다 .때때로 전이학습을 기존 머신러닝 알고리즘의 확장으로 간주하기도 한다. 

전이학습의 정의는 다음과 같다.

한 설정에서 학습한 것을 다른 설정의 일반화를 개선하기 위해 활용하는 것
예를 들면, 주어진 과제가 레스토랑이라는 한정된 도메인의 이미지에서 객체를 확인하는 것이라고 하자. 정의된 범위 안에 있는 이 과제를 T1으로 표시하자. 주어진 데이터 세트를 받아서 모델을 훈련하고 같은 도메인에서는 학습하지 않은 데이터 포인트에서도 잘 작동하도록 튜닝한다. 

기존 머신러닝 알고리즘은 주어진 도메인에 요구되는 과제에서 충분한 훈련 데이터를 가지고 있지 않으면 실패한다. T2의 작업으로부터 객체를 탐지해야 한다고 할 때, 이상적으로는 T1에 대해 훈련된 모델을 적용할 수 있어야 하지만, 실제로는 성능이 저하되고 일반화가 잘되지 않는 상황에 직면한다. 

다양한 이유로 인해 발생되는데 이를 훈련 데이터와 도메인에 대한 모델 편향이라고 한다. 전이학습은 이렇게 이전에 습득한 지식을 활용해 새로운 고나련 과제에 적용할 수 있게 해준다. T1 과제에 대한 데이터가 유의미하게 많으면 T2에 활용할 수 있다. 이미지 분류의 경우 저수준 특성이 작업 간에 공유되므로 작업 간의 지식 전이가 가능하다.

다음 그림은 전이학습을 통해 기존 지식을 새로운 관련 과제에 재사용하는 방법을 보여준다.


소스 과제에서 습득한 지식을 타깃 과제 학습 시 추가로 입력한다.

전이학습의 혜택
전이학습이 이미 만들어진 모델을 재사용하는 기능을 제공하는 것과는 별개로 다음과 같은 방법으로도 타깃 과제의 학습을 도울 수 있다. 

향상된 기본 성능
모델 개발 시간
향상된 최종 성능

전이학습의 개념은 딥러닝에 제한되지 않는다.

전이학습 전략
전이학습을 이해하기 위한 프레임워크를 나타내기 위해 도메인과 과제, 주변부 확률을 사용한다. 프레임 워크는 다음과 같이 정의한다.

도메인 D는 특성공간 x와 주변부 확률 P(X)로 구성된, 요소가 두 개인 튜플로 정의되며, 여기서 X는 샘플의 데이터 포인트다.

x_1는 X={x_1, x_2, ... ,x_n} 이고 특정 벡터 X ∈x 이면 결과는 다음과 같다


반면 과제 T는 레이블 공간 r과 목적 함수 f로 된 요소가 두 개인 튜플로 정의할 수 있다. 이 목적 함수를 확률론적 관점에서 P(r|X) 로 나타낼 수 있다. 따라서 다음과 같이 정의된다.


이 프레임워크를 사용하면 전이학습을 도메인 D_s 에 있는 소스 과제 T_s 의 정보로부터 타깃 도메인 D_r 에 있는 타깃 목적 함수 f_r를 생성하는 것으로 정의할 수 있다. 그러므로 시나리오는 다음과 같이 네 가지가 가능하다.
특성 공간 : 소스 영역이나 타깃 영역의 특성 공간이 서로 다르다. 
주변부 확률 : 주변부 확률이나 소스 영역 및 타깃 영역이 서로 다르다. 이 시나리오를 도메인 적용이라고도 한다.
레이블 공간 : 이 시나리오에서는 소스 도메인과 타깃 도메인의 레이블 공간이 다르다. 이 경우는 보통 다른 조건부 확률에서 네 가지 시나리오가 있을 수 있다.
조건부 확률 : 소스 영역와 타깃 영역에서 조건부 확률이 다른 경우.
전이학습은 타깃 과제의 소스 학습기로부터 얻은 지식을 활용할 수 있다. 전이 학습이 진행되는 동안 세 가지 중요한 질문을 답해야 한다.

전이 항목 : 전체 과정의 시작이며 가장 중요한 단계, 타깃 작업의 성능을 향상시키기 위해 기존 지식의 어떤 부분을 타깃으로 전이할 수 있는지에 대한 해답을 찾는 것, 기존 지식의 어느 부분이 고유한 것이고 기존 지식과 타깃 지식 사이의 공통점이 무엇인지를 알아야 한다.
전이 시기 : 부정적 전이가 발생할 수 있다. 목표 수행의 성과/결과를 저하시키지 않고 향상시키는 것을 전이학습의 활용 목표로 삼아야 한다. 전이의 사용 여부
전이 방법 : 영역/과제 간에 지식을 실제로 전이하는 방법을 알 수 있다. 여기에는 기존 알고리즘과 다른 기술 변경이 포함된다.
전이 학습 방법은 관련 머신러닝 알고리즘의 유형에 따라 다음과 같이 분류할 수 있다.

귀납적 전이 : 이 시나롱는 소스 도메인과 타깃 도메인이 동일하고 과제가 다른 경우에 해당한다. 알고리즘을 통해 소스 도메인의 귀납적 편향을 이용해 타깃 과제 개선을 시도한다. 기존 도메인에 레이블이 지정된 데이터가 있는지에 따라 다중 과제 학습 과 자율 학습의 두 개의 하위 범주로 나눌 수 있다.
비지도 전이 : 타깃 도메인의 비지도 과제에 초점을 맞춘 설정이라는 점에서 귀납적 전이와 유사하다. 소스 도메인과 타깃 도메인은 비슷하지만, 과제는 다르다. 이 시나리오에서 분류된 데이터는 두 도메인 중 하나에서 사용할 수 없다.
변환 전이 : 이 시나리오에서는 소스 작업과 타깃 작업은 비슷하지만, 해당 도멩니이 달라진 경우를 다룬다. 이 설정에서 타깃 도메인에는 분류된 데이터가 없지만, 소스 도메인에는 분류된 데이터가 많다. 이것은 특성 공간이 다르거나 주변부 확률이 다 른 설정을 고려해 하위 범주로 추가 분류할 수 있다.
이러한 범주를 넘어서 무엇을 전이할 것인가에 대한 질문에 답하기 위해 다음 접근법 중 일부를 적용할 수 있다. 

인스턴스 전이 : 소스 도메인의 지식을 타깃 과제에 재사용하는 것이 일반적으로 이상적인 시나리오다. 
특성 표현 전이 : 소스 도메인부터 타깃 도메인 까지 활용할 수 있는 좋은 특성 표현을 알아내서 도메인 분산을 최소화하고 오차율을 줄이는 것을 목표로 한다. 분류된 데이터의 이용 가능성에 따라 지도 또는 비지도 학습 방법이 특성 표현 기반의 전이에 적용될 수 있다.
파라미터 전이 : 과제와 관련된 모델이 파라미터 또는 하이퍼파라미터의 사전 분포를 공유한다는 가정하에 적용된다. 소스와 타깃 작업이 동시에 학습되는 다중 과제 학습과 달리 전이학습에서는 전체 성능을 향상하기 위해 타깃 도메인의 손실에 추가적인 가중치를 적용할 수 있다.
관계형 지식 전이 : 독립적이고 동일하게 분산되지 않은 데이터처럼 독립 항등 분포가 아닌 데이터를 처리하려고 시도한다. 각 데이터 포인트들이 관계가 있다.
전이학습과 딥러닝
딥러닝 모델은 귀납적 학습이라고 알려진 것을 표현한다. 이 알고리즘의 목표는 학습 예제 세트로부터 매핑을 추론하는 것이다. 예를 들어 편향 또는 가정을 제한하는 가설 공간과 그 가설 공간에서의 탐색 프로세스 같은 것들이다. 따라서 편향은 주어진 과제와 도메인에서 모델이 무엇을 어떻게 배우는지에 영향을 준다.

귀납적 전이 기술은 소스 과제의 귀납적 편향을 이용해 타깃 과제를 지원한다. 이것은 모델 공간을 제한해 대상 작업의 귀납적 편향을 조정하거나 가설 공간을 좁히거나 소스 과제의 지식을 활용해 검색 과정 자체를 조정하는 등 여러 가지 방법으로 수행할 수 있다. 그 프로세스를 다음 그림과 같이 나타낼 수 있다.


귀납 전이와는 별도로 귀납적 학습 알고리즘은 베이즈와 계층적 전이 기법을 활용해서 타깃 과제의 학습과 성능을 개선한다.

전이학습의 방법
특성 추출
딥러닝의 체계는 서로 다른 층에서 서로 다른 특성을 학습하는 층이 있는 아키텍쳐다. 최종 출력을 얻기 위해 마지막 층에 연결된다. 이 층 아키텍처 덕분에 최종 층에서 고정된 특성 추출기 없이 사전 훈련된 네트워크를 통해 작업할 수 있다.


예를 들어 최종 분류층 없이 AlexNet을 쓰면 새로운 도메인 영역의 이미지들을 네트워크의 은닉 상태를 기반으로 4,096 차원 벡터로 변환하는 데 도움이 된다. 

미세 튜닝
사전 훈련 모델


